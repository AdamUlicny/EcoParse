
# To simplify your workflow, list here the models you want to use with Ollama and Gemini backends.
# You can add or remove models as needed. Make sure the model names match those available in your Ollama installation or Gemini API access.
# Ollama Models Configuration
ollama_models:
  # Mistral models
  - name: "mistral:instruct"
    description: "Mistral Instruct 7b model"
  - name: "mixtral:8x7b-instruct-v0.1-q8_0"
    description: "Mixtral 8x7b Instruct q8"
  # Qwen models
  - name: "qwen3:30b-a3b-instruct-2507-q4_K_M"
    description: "Qwen 3 30b A3B Instruct model"
  # Llama models
  - name: "llama3.1:8b-instruct-fp16"
    description: "Llama 3.1 8B Instruct FP16 model"
  - name: "llama3.2-vision:11b"
    description: "Llama 3.2 Vision 11B model"
  - name: "llama4:scout"
    description: "Llama 4 Scout model"
  # Granite models
  - name: "granite3.3:8b"
    description: "Granite 8B model"
  - name: "granite3.2-vision:2b"
    description: "Granite 2B Vision model"

# Gemini Models
gemini_models:
  - name: "gemini-2.5-flash"
    description: "Gemini 2.5 Flash model"
  - name: "gemini-2.5-flash-lite"
    description: "Gemini 2.5 Flash Lite model"
  - name: "gemini-2.5-pro" 
    description: "Gemini 2.5 Pro model"
  
